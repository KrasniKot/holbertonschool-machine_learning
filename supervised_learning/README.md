# Supervised Learning
Supervised learning projects are contained in this directory

## Projects:

### Decision Trees:
No data to show

### Classification:
* What is a model?  
* What is supervised learning?  
* What is a prediction?  
* What is a node?  
* What is a weight?  
* What is a bias?  
* What are activation functions?  
  * Sigmoid?  
  * Tanh?  
  * Relu?  
  * Softmax?  
* What is a layer?  
* What is a hidden layer?  
* What is Logistic Regression?  
* What is a loss function?  
* What is a cost function?  
* What is forward propagation?  
* What is Gradient Descent?  
* What is back propagation?  
* What is a Computation Graph?  
* How to initialize weights/biases  
* The importance of vectorization  
* How to split up your data  
* What is multiclass classification?
* What is a one-hot vector?
* How to encode/decode one-hot vectors
* What is the softmax function and when do you use it?
* What is cross-entropy loss?
* What is pickling in Python?

### Tensorflow:
* What is tensorflow?
* What is a session? graph?
* What are tensors?
* What are variables? constants? placeholders? How do you use them?
* What are operations? How do you use them?
* What are namespaces? How do you use them?
* How to train a neural network in tensorflow
* What is a checkpoint?
* How to save/load a model with tensorflow
* What is the graph collection?
* How to add and get variables from the collection

### Optimization:
* What is a hyperparameter?
* How and why do you normalize your input data?
* What is a saddle point?
* What is stochastic gradient descent?
* What is mini-batch gradient descent?
* What is a moving average? How do you implement it?
* What is gradient descent with momentum? How do you implement it?
* What is RMSProp? How do you implement it?
* What is Adam optimization? How do you implement it?
* What is learning rate decay? How do you implement it?
* What is batch normalization? How do you implement it?

## Error Analysis:
* What is the confusion matrix?
* What is type I error? type II?
* What is sensitivity? specificity? precision? recall?
* What is an F1 score?
* What is bias? variance?
* What is irreducible error?
* What is Bayes error?
* How can you approximate Bayes error?
* How to calculate bias and variance
* How to create a confusion matrix

## Regularization:
* What is regularization? What is its purpose?
* What is are L1 and L2 regularization? What is the difference between the two methods?
* What is dropout?
* What is early stopping?
* What is data augmentation?
* How do you implement the above regularization methods in Numpy? Tensorflow?
* What are the pros and cons of the above regularization methods?

## Tensorflow 2 & Keras:
* What is Keras?
* What is a model?
* How to instantiate a model (2 ways)
* How to build a layer
* How to add regularization to a layer
* How to add dropout to a layer
* How to add batch normalization
* How to compile a model
* How to optimize a model
* How to fit a model
* How to use validation data
* How to perform early stopping
* How to measure accuracy
* How to evaluate a model
* How to make a prediction with a model
* How to access the weights/outputs of a model
What is HDF5?
* How to save and load a model’s weights, a model’s configuration, and the entire model

# Convolutional Neural Networks
* What is a convolutional layer?
* What is a pooling layer?
* Forward propagation over convolutional and pooling layers
* Back propagation over convolutional and pooling layers
* How to build a CNN using Tensorflow and Keras 